---
title: "Modeling in the Tidyverse"
subtitle: "Applications of Data Science"
author: "Giora Simchoni"
institute: "Stat. and OR Department, TAU"
date: "`r Sys.Date()`"
output_dir: "images"
output:
  xaringan::moon_reader:
    css: "../slides.css"
    seal: false
    chakra: "../libs/remark-latest.min.js"
    includes:
      in_header: "../header.html"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: logo-slide

---

class: title-slide

## Modeling in the Tidyverse

### Applications of Data Science - Class 5

### Giora Simchoni

#### `gsimchoni@gmail.com and add #dsapps in subject`

### Stat. and OR Department, TAU
### `r Sys.Date()`

---
```{r child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(emoji)
```

class: section-slide

# The Problem

---

### Inconsistency, Inextensibility

```{r GLM-Data}
n <- 10000
x1 <- runif(n)
x2 <- runif(n)
t <- 1 + 2 * x1 + 3 * x2
y <- rbinom(n, 1, 1 / (1 + exp(-t)))
```

```{r GLM, eval=FALSE}
glm(y ~ x1 + x2, family = "binomial")
```

```{r GLMNET, eval=FALSE}
glmnet(as.matrix(cbind(x1, x2)), as.factor(y), family = "binomial")
```

```{r RF, eval=FALSE}
randomForest(as.factor(y) ~ x1 + x2)
```


```{r GBM, eval=FALSE}
gbm(y ~ x1 + x2, data = data.frame(x1 = x1, x2 = x2, y = y))
```

`r emoji("scream")`

---

### Compare this with `sklearn`

```{python, eval=FALSE}
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier,
  GradientBoostingClassifier

LogisticRegression(penalty='none').fit(X, y)

LogisticRegression(penalty='l2', C=0.001).fit(X, y)

RandomForestClassifier(n_estimators=100).fit(X, y)

GradientBoostingClassifier(n_estimators=100).fit(X, y)
```

---

class: section-slide

# Detour: A Regression Problem

---

### Hungarian Blogs: Predicting Feedback

- Dataset was published as part of the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/BlogFeedback) initiative
- Comes from [Buza 2014](http://www.cs.bme.hu/~buza/pdfs/gfkl2012_blogs.pdf)
- 280 numeric heavily engineered features on blogs and posts published in the last 72 hours
- Can we predict no. of comments in the next 24 hours?

<img src="images/hungarian_blog.png" style="width: 70%" />

---

The raw data has over 50K rows: for each blog features like total comments until base time, weekday, words, etc.

We will be predicting `log(fb)` based on all features, no missing values:

```{r, message=FALSE}
blogs_fb <- read_csv("~/BlogFeedback/blogData_train.csv", col_names = FALSE)

blogs_fb <- blogs_fb %>%
  rename(fb = X281, blog_len = X62, sunday = X276) %>%
  mutate(fb = log(fb + 1))

dim(blogs_fb)
```

---

```{r}
glimpse(blogs_fb)
```

---

See the dependent variable distribution:

```{r Bench-Hist, message=FALSE, out.width="100%", fig.asp=0.5}
ggplot(blogs_fb, aes(fb)) +
  geom_histogram(fill = "red", alpha = 0.5, binwidth = 0.5) +
  theme_bw()
```

---

See it vs. say "length of post":

```{r Bench-Age-Equipment, message=FALSE, out.width="100%", fig.asp=0.5}
ggplot(blogs_fb, aes(log(blog_len), fb)) +
  geom_point(color = "red", alpha = 0.5) +
  theme_bw()
```

---

class: section-slide

# End of Detour

---

# WARNING

.warning[
`r emoji("bulb")` What you're about to see is not a good modeling/prediction flow.

This is just an intro to tidy modeling.

Some of the issues with how things are done here will be raised, some will have to wait till later in the course.
]
---

class: section-slide

# The ~~Present~~ Past Solution: `caret`

---

### Split Data

```{r, message=FALSE, warning=FALSE}
library(caret)

train_idx <- createDataPartition(blogs_fb$fb,
                                 p = 0.6, list = FALSE)

blogs_tr <- blogs_fb[train_idx, ]
blogs_te <- blogs_fb[-train_idx, ]

library(glue)
glue("train no. of rows: {nrow(blogs_tr)}
     test no. of rows: {nrow(blogs_te)}")
```

Here you might consider some preprocessing.

`caret` has some nice documentation [here](https://topepo.github.io/caret/index.html).

---

### Tuning and Modeling

Define general methodology, e.g. 5-fold Cross-Validation:

```{r, warning=FALSE}
fit_control <- trainControl(method = "cv", number = 5)

ridge_grid <- expand.grid(alpha=0, lambda = 10^seq(-3, 1, length = 50))
lasso_grid <- expand.grid(alpha=1, lambda = 10^seq(-3, 1, length = 50))
rf_grid <- expand.grid(splitrule = "variance",
                       min.node.size = seq(10, 30, 10),
                       mtry = seq(10, 50, 20))

mod_ridge <- train(fb ~ ., data = blogs_tr, method = "glmnet",
                trControl = fit_control, tuneGrid = ridge_grid,
                metric = "RMSE")

mod_lasso <- train(fb ~ ., data = blogs_tr, method = "glmnet",
                trControl = fit_control, tuneGrid = lasso_grid,
                metric = "RMSE")

mod_rf <- train(fb ~ ., data = blogs_tr, method = "ranger",
                trControl = fit_control, tuneGrid = rf_grid,
                num.trees = 50, metric = "RMSE")
```

---

### Evaluating Models

```{r}
mod_ridge
```

---

```{r}
mod_lasso
```

---

```{r}
mod_rf
```

---

```{r Ridge-CV, fig.asp=0.5, out.width="80%"}
plot(mod_ridge)
```

---

```{r Lasso-CV, fig.asp=0.5, out.width="80%"}
plot(mod_lasso)
```

---

```{r RF-CV, fig.asp=0.5, out.width="80%"}
plot(mod_rf)
```

---

### Comparing Models

```{r}
resamps <- resamples(list(Ridge = mod_ridge, Lasso = mod_lasso,
                          RF = mod_rf))
summary(resamps)
```

---

```{r Caret-RMSE-Comp, fig.asp=0.5, out.width="100%"}
dotplot(resamps, metric = "RMSE")
```

---

### Predicting

```{r}
pred_ridge <- predict(mod_ridge, newdata = blogs_te)
pred_lasso <- predict(mod_lasso, newdata = blogs_te)
pred_rf <- predict(mod_rf, newdata = blogs_te)

rmse_ridge <- RMSE(pred_ridge, blogs_te$fb)
rmse_lasso <- RMSE(pred_lasso, blogs_te$fb)
rmse_rf <- RMSE(pred_rf, blogs_te$fb)

glue("Test RMSE Ridge: {format(rmse_ridge, digits = 3)}
     Test RMSE Lassoe: {format(rmse_lasso, digits = 3)}
     Test RMSE RF: {format(rmse_rf, digits = 3)}")
```

---

```{r Caret-Pred-vs-True, message=FALSE, warning=FALSE, fig.asp=0.5, out.width="100%"}
bind_rows(
  tibble(method = "Ridge", pred = pred_ridge, true = blogs_te$fb),
  tibble(method = "Lasso", pred = pred_lasso, true = blogs_te$fb),
  tibble(method = "RF", pred = pred_rf, true = blogs_te$fb)) %>%
  ggplot(aes(true, pred)) +
  geom_point(color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0) +
  facet_wrap(~ factor(method, levels = c("Ridge", "Lasso", "RF"))) +
  theme_bw()
```

---

class: section-slide

# The ~~Future~~ Present Solution: `tidymodels`

#### Inspired by [Julia Silge](https://juliasilge.com/blog/intro-tidymodels/)

---

### Packages under tidymodels

- `parsnip`: tidy `caret`
- `dials` and `tune`: specifying and tuning model parameters
- `rsample`: sampling, data partitioning
- `recipes`, `embed`, `themis`: preprocessing and creating model matrices
- `infer`: tidy statistics
- `yardstick`: measuring models performance
- `broom`: convert models output into tidy tibbles

And [more](https://www.tidymodels.org/).

.warning[
`r emoji("warning")` All `tidymodels` packages are under development!
]

---

### Split Data

The `initial_split()` function is from the `rsample` package:

```{r, message=FALSE, warning=FALSE}
library(tidymodels)

blogs_split_obj <- blogs_fb %>%
  initial_split(prop = 0.6)

print(blogs_split_obj)

blogs_tr <- training(blogs_split_obj)
blogs_te <- testing(blogs_split_obj)

glue("train no. of rows: {nrow(blogs_tr)}
     test no. of rows: {nrow(blogs_te)}")
```

---

### Preprocess .font80percent[(but we're not gonna use it)]

The `recipe()` function is from the `recipes` package. It allows you to specify a sklearn-like pipe you can later apply to any dataset, including all preprocessing steps:

```{r}
blogs_rec <- recipe(fb ~ ., data = blogs_tr)
blogs_rec
```

`recipes` contains more preprocessing [`step_`s](https://tidymodels.github.io/recipes/reference/index.html) than you imagine:

```{r}
blogs_rec <-  blogs_rec %>%
  step_zv(all_numeric()) %>%
  step_normalize(all_numeric())
```

---

After you have your `recipe` you need to `prep()` materials...

```{r}
blogs_rec <- blogs_rec %>% prep(blogs_tr)

blogs_rec
```

At this point our `recipe` has all necessary `sd` and `mean`s for numeric variables.

---

```{r}
blogs_rec$var_info
```

---

```{r}
blogs_rec$steps[[2]]$means |> head()
blogs_rec$steps[[2]]$sds |> head()
```

---

And then we `bake()` (or [`juice()`](https://tidymodels.github.io/recipes/reference/juice.html)):

```{r}
blogs_tr2 <- blogs_rec %>% bake(blogs_tr)
blogs_te2 <- blogs_rec %>% bake(blogs_te)

glue("mean of comments in orig training: {format(mean(blogs_tr$X51), digits = 3)}, sd: {format(sd(blogs_tr$X51), digits = 3)}
     mean of comments in baked training: {format(mean(blogs_tr2$X51), digits = 1)}, sd: {format(sd(blogs_tr2$X51), digits = 3)}")

glue("mean of comments in orig testing: {format(mean(blogs_te$X51), digits = 3)}, sd: {format(sd(blogs_te$X51), digits = 3)}
     mean of comments in baked testing: {format(mean(blogs_te2$X51), digits = 1)}, sd: {format(sd(blogs_te2$X51), digits = 3)}")
```

---

Or you can do it all in a single pipe:

```{r}
blogs_rec <- recipe(fb ~ ., data = blogs_tr) %>%
  step_zv(all_numeric()) %>%
  step_normalize(all_numeric()) %>%
  prep(blogs_tr)

blogs_tr2 <- blogs_rec %>% bake(blogs_tr)
blogs_te2 <- blogs_rec %>% bake(blogs_te)

glue("mean of comments in orig training: {format(mean(blogs_tr$X51), digits = 3)}, sd: {format(sd(blogs_tr$X51), digits = 3)}
     mean of comments in baked training: {format(mean(blogs_tr2$X51), digits = 1)}, sd: {format(sd(blogs_tr2$X51), digits = 3)}")

glue("mean of comments in orig testing: {format(mean(blogs_te$X51), digits = 3)}, sd: {format(sd(blogs_te$X51), digits = 3)}
     mean of comments in baked testing: {format(mean(blogs_te2$X51), digits = 1)}, sd: {format(sd(blogs_te2$X51), digits = 3)}")
```

---

#### Fast Forward 10 weeks from now...

```{r, eval=FALSE}
rec_int_topints <- recipe(pets ~ ., data = okcupid_tr) %>%
  step_textfeature(essays, prefix = "t",
                   extract_functions = my_text_funs) %>%
  update_role(essays, new_role = "discarded") %>%
  step_mutate_at(starts_with("t_"), fn = ~ifelse(is.na(.x), 0, .x)) %>%
  step_log(income, starts_with("len_"), starts_with("t_"),
           -t_essays_sent_bing, offset = 1) %>%
  step_meanimpute(income) %>%
  step_other(
    all_nominal(), -has_role("discarded"), -all_outcomes(),
    other = "all_else", threshold = 0.1) %>%
  step_novel(
    all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE) %>%
  step_interact(topint_ints) %>%
  step_nzv(all_numeric(), freq_cut = 99/1) %>%
  step_upsample(pets, over_ratio = 1, seed = 42)
```

---

### Modeling

For now let us use the original `blogs_tr` data.

Functions `linear_reg()` and `set_engine()` are from the `parsnip` package:

```{r}
mod_ridge_spec <- linear_reg(mixture = 0, penalty = 0.001) %>%
  set_engine(engine = "glmnet")

mod_ridge_spec
```

---

```{r}
mod_ridge <- mod_ridge_spec %>%
  fit(fb ~ ., data = blogs_tr)

mod_ridge
```

---

In a single pipe:

```{r}
mod_lasso <- linear_reg(mixture = 1, penalty = 0.001) %>%
  set_engine(engine = "glmnet") %>%
  fit(fb ~ ., data = blogs_tr)

mod_lasso
```

---

Can also use `fit_xy()` a-la `sklearn`:

```{r}
mod_rf <- rand_forest(mode = "regression", mtry = 50, trees = 50, min_n = 10) %>%
  set_engine("ranger") %>%
  fit_xy(x = blogs_tr[, -281],
         y = blogs_tr$fb)

mod_rf
```

---

Notice how easy it is to get the model's results in a tidy way using the `tidy()` function:

```{r, message=FALSE}
tidy(mod_ridge)
```

---

### Predicting

```{r}
results_test <- mod_ridge %>%
  predict(new_data = blogs_te, penalty = 0.001) %>%
  mutate(
    truth = blogs_te$fb,
    method = "Ridge"
  ) %>%
  bind_rows(mod_lasso %>%
    predict(new_data = blogs_te) %>%
    mutate(
      truth = blogs_te$fb,
      method = "Lasso"
  )) %>%
  bind_rows(mod_rf %>%
    predict(new_data = blogs_te) %>%
    mutate(
      truth = blogs_te$fb,
      method = "RF"
  ))

dim(results_test)

head(results_test)
```

---

### Comparing Models

The package `yardstick` has tons of performance [metrics](https://tidymodels.github.io/yardstick/articles/metric-types.html):

```{r}
results_test %>%
  group_by(method) %>%
  rmse(truth = truth, estimate = .pred)
```

---

```{r Tidymodels-Pred-vs-True, message=FALSE, warning=FALSE, fig.asp=0.5, out.width="100%"}
results_test %>%
  ggplot(aes(truth, .pred)) +
  geom_point(color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0) +
  facet_wrap(~ factor(method, levels = c("Ridge", "Lasso", "RF"))) +
  theme_bw()
```

---

### Tuning

Define your model spec, using `tune()` from the `tune` package for a parameter you wish to tune:

```{r, message=FALSE, warning=FALSE}
mod_rf_spec <- rand_forest(mode = "regression",
                           mtry = tune(),
                           min_n = tune(),
                           trees = 100) %>%
  set_engine("ranger")
```

---

Define the `grid` on which you train your params, with the `dials` package:

```{r}
rf_grid <- grid_regular(mtry(range(10, 70)), min_n(range(10, 30)),
                        levels = c(4, 3))

rf_grid
```

---

Split your data into a few folds for Cross Validation with `vfold_cv()` from the `rsample` package:

```{r}
cv_splits <- vfold_cv(blogs_tr, v = 5)

cv_splits
```

---

Now perform cross validation with `tune_grid()` from the `tune` package:

```{r, eval=FALSE}
tune_res <- tune_grid(mod_rf_spec,
                      recipe(fb ~ ., data = blogs_tr),
                      resamples = cv_splits,
                      grid = rf_grid,
                      metrics = metric_set(rmse))
tune_res
```

```{r echo=FALSE}
tune_res <- read_rds("~/blogs_rfmod_tune.rds")
tune_res
```

---

```{r}
tune_res$.metrics[[1]]
```

---

Collect the mean metric across folds:

```{r}
estimates <- collect_metrics(tune_res)

estimates
```

---

Choose best parameter:

```{r Tidymodels-RMSE-Comp, fig.asp=0.5, out.width="100%"}
estimates %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(x = mtry, y = mean, color = min_n)) + 
  geom_point() + 
  geom_line() + 
  labs(y = "Mean RMSE") +
  theme_bw()
```

---

There are of course also methods for helping us choose best params and final model.

```{r}
best_rmse <- tune_res %>% select_best(metric = "rmse")
best_rmse
```

See also `?select_by_one_std_err`.

```{r}
mod_rf_final <- finalize_model(mod_rf_spec, best_rmse)
mod_rf_final
```

---

```{r, eval=FALSE}
mod_rf_final %>%
  fit(fb ~ ., data = blogs_tr) %>%
  predict(new_data = blogs_te) %>%
  mutate(truth = blogs_te$fb) %>%
  head(10)
```

```{r, echo=FALSE, message=FALSE}
read_rds("../data/blogs_mod_rf_te_pred.rds")
```

---

### Book (WIP?)

<img src="images/tmwr.png" style="width: 45%" />

https://www.tmwr.org/

---

class: section-slide

# `infer`: Tidy Statistics

---

### Statistical Q1

Is there a relation between posts published on Sundays and blogger hand dominance, where hand dominance is totally made up? `r emoji("grimacing")`

```{r, echo=FALSE}
blogs_fb <- blogs_fb %>%
  mutate(hand = sample(c("left", "right"), n(),
                       prob = c(0.1, 0.9), replace = T),
         sunday = factor(ifelse(sunday, "S", "NS")))
```

```{r}
pub_vs_hand <- blogs_fb %>%
  select(sunday, hand) %>%
  table()

pub_vs_hand
```

```{r}
prop.table(pub_vs_hand, margin = 1)
```

---

### Statistical Q2

Is there a difference in feedback between posts published on Sundays and posts published on another day?

```{r}
blogs_fb %>%
  group_by(sunday) %>% summarise(avg = mean(fb), sd = sd(fb), n = n())
```

---

### Same Problem!

Varied interface, varied output.

```{r}
prop.test(pub_vs_hand[,1], rowSums(pub_vs_hand))
```

---

```{r}
t.test(fb ~ sunday, data = blogs_fb)
```

---

### The `generics::tidy()` Approach

(Also available when you load several other packages, like `broom` and `yardstick`)

```{r}
tidy(prop.test(pub_vs_hand[,1], rowSums(pub_vs_hand)))
```

```{r}
tidy(t.test(fb ~ sunday, data = blogs_fb))
```

---

### The `infer` Approach

> infer implements an expressive grammar to perform statistical inference that coheres with the tidyverse design framework

4 main verbs for a typical flow:

* `specify()` - dependent/independent variables, formula
* `hypothesize()` - declare the null hypothesis
* `generate()` - generate data reflecting the null hypothesis (the permutation/bootstrap approach)
* `calculate()` - calculate a distribution of statistics from the generated data, from which you can extract conclusion based on a p-value for example

---

### `infer` Diff in Proportions Test

Get the observed statistic (here manually in order to not confuse you, there *is* a way via `infer`):

```{r}
pub_vs_hand
```

```{r}
p_NS <- pub_vs_hand[1, 1] / (sum(pub_vs_hand[1, ]))
p_S <- pub_vs_hand[2, 1] / (sum(pub_vs_hand[2, ]))
obs_diff <- p_NS - p_S
obs_diff
```

---

Get distribution of the difference in proportions under null hypothesis

```{r}
diff_null_perm <- blogs_fb %>%
  specify(hand ~ sunday, success = "left") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 200, type = "permute") %>%
  calculate(stat = "diff in props", order = c("NS", "S"))

diff_null_perm
```

---

Visualize the permuted difference null distribution and the p-value

```{r Diff-in-Props-Null, out.width="50%"}
visualize(diff_null_perm) +
  shade_p_value(obs_stat = obs_diff, direction = "two_sided")
```

---

Get the actual p-value:

```{r}
diff_null_perm %>% 
  get_p_value(obs_stat = obs_diff, direction = "two_sided")
```

---

### `infer` t Test (independent samples)

Get the observed statistic (here via `infer`):

```{r}
obs_t <- blogs_fb %>%
  specify(fb ~ sunday) %>%
  calculate(stat = "t", order = c("NS", "S"))
obs_t
```


---

Get distribution of the t statistic under null hypothesis

```{r}
t_null_perm <- blogs_fb %>%
  specify(fb ~ sunday) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 100, type = "permute") %>%
  calculate(stat = "t", order = c("NS", "S"))

t_null_perm
```

---

Visualize the permuted t statistic null distribution and the two-sided p-value

```{r T-Null, out.width="50%"}
visualize(t_null_perm) +
  shade_p_value(obs_stat = obs_t, direction = "two_sided")
```

---

Get the actual p-value:

```{r}
t_null_perm %>% 
  get_p_value(obs_stat = obs_t, direction = "two_sided")
```
